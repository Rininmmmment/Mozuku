{"ast":null,"code":"// import React, { useEffect, useRef, useState } from 'react';\n\n// function WebcamCapture() {\n//   const videoRef = useRef<HTMLVideoElement | null>(null);\n//   const canvasRef = useRef<HTMLCanvasElement | null>(null);\n//   const [result, setResult] = useState<string>('');\n\n//   useEffect(() => {\n//     const startWebcam = async () => {\n//       try {\n//         const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n//         if (videoRef.current) {\n//           videoRef.current.srcObject = stream;\n//         }\n//       } catch (error) {\n//         console.error('Error accessing webcam:', error);\n//       }\n//     };\n\n//     startWebcam();\n//   }, []);\n\n//   const captureVideoFrame = async () => {\n//     const canvas = canvasRef.current;\n//     const video = videoRef.current;\n\n//     if (canvas && video) {\n//       const ctx = canvas.getContext('2d');\n//       if (ctx) {\n//         ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n//         // Canvasから画像データを取得\n//         const imageDataURL = canvas.toDataURL('image/jpeg');\n\n//         // 画像データを送信\n//         const response = await fetch('http://localhost:8000/face-detection', {\n//           method: 'POST',\n//           body: JSON.stringify({ image: imageDataURL }),\n//           headers: {\n//             'Content-Type': 'application/json',\n//           },\n//         });\n\n//         if (response.ok) {\n//           const data = await response.json();\n//           if (data.result === 'Yes') {\n//             setResult('会いに来てくれたんだね！嬉しいにゃ〜');\n//           } else {\n//             setResult('遊んでくれなくて悲しいにゃ...');\n//           }\n//         } else {\n//           console.error('Error sending image for analysis');\n//         }\n//       }\n//     }\n//   };\n\n//   useEffect(() => {\n//     // 10秒ごとにcaptureVideoFrameを呼び出すタイマーを設定\n//     const timer = setInterval(captureVideoFrame, 10000);\n\n//     // コンポーネントがアンマウントされたときにタイマーをクリア\n//     return () => {\n//       clearInterval(timer);\n//     };\n//   }, []);\n\n//   return (\n//     <div>\n//       <button onClick={captureVideoFrame}>Capture and Analyze</button>\n//       <video style={{ display: 'none' }} ref={videoRef} autoPlay />\n//       <canvas ref={canvasRef} style={{ display: 'none' }} />\n//       <p>もずく: {result}</p>\n//     </div>\n//   );\n// }\n\n// export default WebcamCapture;\n\n// import React, { useEffect, useRef } from 'react';\n// import * as THREE from 'three';\n\n// function ThreeDObject() {\n//   const canvasRef = useRef<HTMLCanvasElement | null>(null);\n\n//   useEffect(() => {\n//     const canvas = canvasRef.current;\n//     if (!canvas) return;\n\n//     // シーンの作成\n//     const scene = new THREE.Scene();\n\n//     // カメラの作成\n//     const camera = new THREE.PerspectiveCamera(75, canvas.clientWidth / canvas.clientHeight, 0.1, 1000);\n//     camera.position.z = 5;\n\n//     // レンダラの作成\n//     const renderer = new THREE.WebGLRenderer({ canvas });\n\n//     // 立方体の作成\n//     const geometry = new THREE.BoxGeometry();\n//     const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });\n//     const cube = new THREE.Mesh(geometry, material);\n//     scene.add(cube);\n\n//     // アニメーションの設定\n//     const animate = () => {\n//       requestAnimationFrame(animate);\n\n//       // 立方体を回転させる\n//       cube.rotation.x += 0.01;\n//       cube.rotation.y += 0.01;\n\n//       // レンダリング\n//       renderer.render(scene, camera);\n//     };\n\n//     animate();\n//   }, []);\n\n//   return <canvas ref={canvasRef} style={{ display: 'block', width: '100%' }} />;\n// }\n\n// export default ThreeDObject;","map":{"version":3,"names":[],"sources":["/usr/src/app/src/App.tsx"],"sourcesContent":["// import React, { useEffect, useRef, useState } from 'react';\n\n// function WebcamCapture() {\n//   const videoRef = useRef<HTMLVideoElement | null>(null);\n//   const canvasRef = useRef<HTMLCanvasElement | null>(null);\n//   const [result, setResult] = useState<string>('');\n\n//   useEffect(() => {\n//     const startWebcam = async () => {\n//       try {\n//         const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n//         if (videoRef.current) {\n//           videoRef.current.srcObject = stream;\n//         }\n//       } catch (error) {\n//         console.error('Error accessing webcam:', error);\n//       }\n//     };\n\n//     startWebcam();\n//   }, []);\n\n//   const captureVideoFrame = async () => {\n//     const canvas = canvasRef.current;\n//     const video = videoRef.current;\n\n//     if (canvas && video) {\n//       const ctx = canvas.getContext('2d');\n//       if (ctx) {\n//         ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n//         // Canvasから画像データを取得\n//         const imageDataURL = canvas.toDataURL('image/jpeg');\n\n//         // 画像データを送信\n//         const response = await fetch('http://localhost:8000/face-detection', {\n//           method: 'POST',\n//           body: JSON.stringify({ image: imageDataURL }),\n//           headers: {\n//             'Content-Type': 'application/json',\n//           },\n//         });\n\n//         if (response.ok) {\n//           const data = await response.json();\n//           if (data.result === 'Yes') {\n//             setResult('会いに来てくれたんだね！嬉しいにゃ〜');\n//           } else {\n//             setResult('遊んでくれなくて悲しいにゃ...');\n//           }\n//         } else {\n//           console.error('Error sending image for analysis');\n//         }\n//       }\n//     }\n//   };\n\n//   useEffect(() => {\n//     // 10秒ごとにcaptureVideoFrameを呼び出すタイマーを設定\n//     const timer = setInterval(captureVideoFrame, 10000);\n\n//     // コンポーネントがアンマウントされたときにタイマーをクリア\n//     return () => {\n//       clearInterval(timer);\n//     };\n//   }, []);\n\n//   return (\n//     <div>\n//       <button onClick={captureVideoFrame}>Capture and Analyze</button>\n//       <video style={{ display: 'none' }} ref={videoRef} autoPlay />\n//       <canvas ref={canvasRef} style={{ display: 'none' }} />\n//       <p>もずく: {result}</p>\n//     </div>\n//   );\n// }\n\n// export default WebcamCapture;\n\n\n// import React, { useEffect, useRef } from 'react';\n// import * as THREE from 'three';\n\n\n// function ThreeDObject() {\n//   const canvasRef = useRef<HTMLCanvasElement | null>(null);\n\n//   useEffect(() => {\n//     const canvas = canvasRef.current;\n//     if (!canvas) return;\n\n//     // シーンの作成\n//     const scene = new THREE.Scene();\n\n//     // カメラの作成\n//     const camera = new THREE.PerspectiveCamera(75, canvas.clientWidth / canvas.clientHeight, 0.1, 1000);\n//     camera.position.z = 5;\n\n//     // レンダラの作成\n//     const renderer = new THREE.WebGLRenderer({ canvas });\n\n//     // 立方体の作成\n//     const geometry = new THREE.BoxGeometry();\n//     const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });\n//     const cube = new THREE.Mesh(geometry, material);\n//     scene.add(cube);\n\n//     // アニメーションの設定\n//     const animate = () => {\n//       requestAnimationFrame(animate);\n\n//       // 立方体を回転させる\n//       cube.rotation.x += 0.01;\n//       cube.rotation.y += 0.01;\n\n//       // レンダリング\n//       renderer.render(scene, camera);\n//     };\n\n//     animate();\n//   }, []);\n\n//   return <canvas ref={canvasRef} style={{ display: 'block', width: '100%' }} />;\n// }\n\n// export default ThreeDObject;\n\n"],"mappings":"AAAA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;;AAGA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA"},"metadata":{},"sourceType":"module","externalDependencies":[]}